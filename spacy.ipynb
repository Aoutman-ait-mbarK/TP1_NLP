{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e5d2c1",
   "metadata": {},
   "source": [
    "# TP1 Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f93374",
   "metadata": {},
   "source": [
    "spaCy is a library for advanced Natural Language Processing in Python and Cython. It's built on the very latest research, and was designed from day one to be used in real products. spaCy comes with pretrained statistical models and word vectors, and currently supports tokenization for 60+ languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd052435",
   "metadata": {},
   "outputs": [],
   "source": [
    "## install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9d0b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (8.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01037542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.ar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695509e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.20.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.59.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485aa1b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c787abe1",
   "metadata": {},
   "source": [
    "# tokenize text by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302b336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating English module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c5a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.59.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.20.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531cdb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text= \"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely \n",
    "the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from \n",
    "the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational \n",
    "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new \n",
    "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the \n",
    "subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a \n",
    "way which had not happened before.\n",
    "\"\"\"\n",
    " \n",
    "arabic_text=\"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي و هي بدايات الجبر، و من المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن المفهوم اليوناني للرياضيات التي هي في جوهرها هندسة، الجبر كان نظرية موحدة تتيح الأعداد الكسرية و الأعداد اللا كسرية، و قدم وسيلة للتنمية في هذا الموضوع مستقبلا. و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545f6cf",
   "metadata": {},
   "source": [
    "# tokenize english text by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992dc601",
   "metadata": {},
   "outputs": [],
   "source": [
    " #instantiating English module\n",
    "nlp = spacy.load(\"en_core_web_sm\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "058c5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating doc object containing our token features\n",
    "doc = nlp(english_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d585932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perhaps\n",
      "one\n",
      "of\n",
      "the\n",
      "most\n",
      "significant\n",
      "advances\n",
      "made\n",
      "by\n",
      "Arabic\n",
      "mathematics\n",
      "began\n",
      "at\n",
      "this\n",
      "time\n",
      "with\n",
      "the\n",
      "work\n",
      "of\n",
      "al\n",
      "-\n",
      "Khwarizmi\n",
      ",\n",
      "namely\n",
      "\n",
      "\n",
      "the\n",
      "beginnings\n",
      "of\n",
      "algebra\n",
      ".\n",
      "It\n",
      "is\n",
      "important\n",
      "to\n",
      "understand\n",
      "just\n",
      "how\n",
      "significant\n",
      "this\n",
      "new\n",
      "idea\n",
      "was\n",
      ".\n",
      "It\n",
      "was\n",
      "a\n",
      "revolutionary\n",
      "move\n",
      "away\n",
      "from\n",
      "\n",
      "\n",
      "the\n",
      "Greek\n",
      "concept\n",
      "of\n",
      "mathematics\n",
      "which\n",
      "was\n",
      "essentially\n",
      "geometry\n",
      ".\n",
      "Algebra\n",
      "was\n",
      "a\n",
      "unifying\n",
      "theory\n",
      "which\n",
      "allowed\n",
      "rational\n",
      "\n",
      "\n",
      "numbers\n",
      ",\n",
      "irrational\n",
      "numbers\n",
      ",\n",
      "geometrical\n",
      "magnitudes\n",
      ",\n",
      "etc\n",
      ".\n",
      ",\n",
      "to\n",
      "all\n",
      "be\n",
      "treated\n",
      "as\n",
      "\"\n",
      "algebraic\n",
      "objects\n",
      "\"\n",
      ".\n",
      "It\n",
      "gave\n",
      "mathematics\n",
      "a\n",
      "whole\n",
      "new\n",
      "\n",
      "\n",
      "development\n",
      "path\n",
      "so\n",
      "much\n",
      "broader\n",
      "in\n",
      "concept\n",
      "to\n",
      "that\n",
      "which\n",
      "had\n",
      "existed\n",
      "before\n",
      ",\n",
      "and\n",
      "provided\n",
      "a\n",
      "vehicle\n",
      "for\n",
      "future\n",
      "development\n",
      "of\n",
      "the\n",
      "\n",
      "\n",
      "subject\n",
      ".\n",
      "Another\n",
      "important\n",
      "aspect\n",
      "of\n",
      "the\n",
      "introduction\n",
      "of\n",
      "algebraic\n",
      "ideas\n",
      "was\n",
      "that\n",
      "it\n",
      "allowed\n",
      "mathematics\n",
      "to\n",
      "be\n",
      "applied\n",
      "to\n",
      "itself\n",
      "in\n",
      "a\n",
      "\n",
      "\n",
      "way\n",
      "which\n",
      "had\n",
      "not\n",
      "happened\n",
      "before\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating and updating our list of tokens using list comprehension\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f21af1",
   "metadata": {},
   "source": [
    "# tokenize arabic text by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f2ae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ربما', 'كانت', 'أحد', 'أهم', 'التطورات', 'التي', 'قامت', 'بها', 'الرياضيات', 'العربية', 'التي', 'بدأت', 'في', 'هذا', 'الوقت', 'بعمل', 'الخوارزمي', 'و', 'هي', 'بدايات', 'الجبر', '،', 'و', 'من', 'المهم', 'فهم', 'كيف', 'كانت', 'هذه', 'الفكرة', 'الجديدة', 'مهمة', '،', 'فقد', 'كانت', 'خطوة', 'ثورية', 'بعيدا', 'عن', 'المفهوم', 'اليوناني', 'للرياضيات', 'التي', 'هي', 'في', 'جوهرها', 'هندسة', '،', 'الجبر', 'كان', 'نظرية', 'موحدة', 'تتيح', 'الأعداد', 'الكسرية', 'و', 'الأعداد', 'اللا', 'كسرية', '،', 'و', 'قدم', 'وسيلة', 'للتنمية', 'في', 'هذا', 'الموضوع', 'مستقبلا', '.', 'و', 'جانب', 'آخر', 'مهم', 'لإدخال', 'أفكار', 'الجبر', 'و', 'هو', 'أنه', 'سمح', 'بتطبيق', 'الرياضيات', 'على', 'نفسها', 'بطريقة', 'لم', 'تحدث', 'من', 'قبل']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "doc = nlp(arabic_text)\n",
    "words = [token.text for token in doc]\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bbc61",
   "metadata": {},
   "source": [
    "# Sentence Tokenizing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d2b541d",
   "metadata": {},
   "source": [
    " Sentence tokenization is the process of splitting text into individual sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5141a",
   "metadata": {},
   "source": [
    "# ----------------------tokenize english text by sentence--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae4fb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely \n",
      "the beginnings of algebra.\n",
      "---\n",
      "It is important to understand just how significant this new idea was.\n",
      "---\n",
      "It was a revolutionary move away from \n",
      "the Greek concept of mathematics which was essentially geometry.\n",
      "---\n",
      "Algebra was a unifying theory which allowed rational \n",
      "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\".\n",
      "---\n",
      "It gave mathematics a whole new \n",
      "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the \n",
      "subject.\n",
      "---\n",
      "Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a \n",
      "way which had not happened before.\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(english_text)\n",
    "\n",
    "for sent in doc.sents:\n",
    "  print(sent.text)\n",
    "  print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc59a8e8",
   "metadata": {},
   "source": [
    "# tokenize arabic text by sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f19e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي و هي بدايات الجبر،\n",
      "--\n",
      "و من المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن المفهوم اليوناني للرياضيات التي\n",
      "--\n",
      "هي في جوهرها هندسة، الجبر\n",
      "--\n",
      "كان نظرية موحدة تتيح الأعداد الكسرية و الأعداد اللا كسرية، و قدم وسيلة للتنمية في هذا الموضوع مستقبلا.\n",
      "--\n",
      "و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(arabic_text)\n",
    "\n",
    "for sent in doc.sents:\n",
    "  print(sent.text)\n",
    "  print(\"--\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd968c0",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0677f",
   "metadata": {},
   "source": [
    "Lemmatization:\n",
    "\n",
    "It is a process of grouping together the inflected forms of a word so they can be analyzed as a single item, identified by the word’s lemma, or dictionary form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db7619",
   "metadata": {},
   "source": [
    "# Lemmatization english text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc34a712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Perhaps', 'ADV', 'perhaps', 'n'], ['one', 'NUM', 'one', 'n'], ['of', 'ADP', 'of', 'n'], ['the', 'DET', 'the', 'n'], ['most', 'ADV', 'most', 'n'], ['significant', 'ADJ', 'significant', 'n'], ['advances', 'NOUN', 'advance', 'n'], ['made', 'VERB', 'make', 'n'], ['by', 'ADP', 'by', 'n'], ['Arabic', 'ADJ', 'arabic', 'n'], ['mathematics', 'NOUN', 'mathematic', 'n'], ['began', 'VERB', 'begin', 'n'], ['at', 'ADP', 'at', 'n'], ['this', 'DET', 'this', 'n'], ['time', 'NOUN', 'time', 'n'], ['with', 'ADP', 'with', 'n'], ['the', 'DET', 'the', 'n'], ['work', 'NOUN', 'work', 'n'], ['of', 'ADP', 'of', 'n'], ['al', 'PROPN', 'al', 'n'], ['-', 'PUNCT', '-', 'n'], ['Khwarizmi', 'PROPN', 'Khwarizmi', 'n'], [',', 'PUNCT', ',', 'n'], ['namely', 'ADV', 'namely', 'n'], ['\\n', 'SPACE', '\\n', 'n'], ['the', 'DET', 'the', 'n'], ['beginnings', 'NOUN', 'beginning', 'n'], ['of', 'ADP', 'of', 'n'], ['algebra', 'PROPN', 'algebra', 'n'], ['.', 'PUNCT', '.', 'n'], ['It', 'PRON', 'it', 'n'], ['is', 'AUX', 'be', 'n'], ['important', 'ADJ', 'important', 'n'], ['to', 'PART', 'to', 'n'], ['understand', 'VERB', 'understand', 'n'], ['just', 'ADV', 'just', 'n'], ['how', 'ADV', 'how', 'n'], ['significant', 'ADJ', 'significant', 'n'], ['this', 'DET', 'this', 'n'], ['new', 'ADJ', 'new', 'n'], ['idea', 'NOUN', 'idea', 'n'], ['was', 'AUX', 'be', 'n'], ['.', 'PUNCT', '.', 'n'], ['It', 'PRON', 'it', 'n'], ['was', 'AUX', 'be', 'n'], ['a', 'DET', 'a', 'n'], ['revolutionary', 'ADJ', 'revolutionary', 'n'], ['move', 'NOUN', 'move', 'n'], ['away', 'ADV', 'away', 'n'], ['from', 'ADP', 'from', 'n'], ['\\n', 'SPACE', '\\n', 'n'], ['the', 'DET', 'the', 'n'], ['Greek', 'ADJ', 'greek', 'n'], ['concept', 'NOUN', 'concept', 'n'], ['of', 'ADP', 'of', 'n'], ['mathematics', 'NOUN', 'mathematic', 'n'], ['which', 'DET', 'which', 'n'], ['was', 'VERB', 'be', 'n'], ['essentially', 'ADV', 'essentially', 'n'], ['geometry', 'NOUN', 'geometry', 'n'], ['.', 'PUNCT', '.', 'n'], ['Algebra', 'PROPN', 'Algebra', 'n'], ['was', 'AUX', 'be', 'n'], ['a', 'DET', 'a', 'n'], ['unifying', 'ADJ', 'unifying', 'n'], ['theory', 'NOUN', 'theory', 'n'], ['which', 'DET', 'which', 'n'], ['allowed', 'VERB', 'allow', 'n'], ['rational', 'ADJ', 'rational', 'n'], ['\\n', 'SPACE', '\\n', 'n'], ['numbers', 'NOUN', 'number', 'n'], [',', 'PUNCT', ',', 'n'], ['irrational', 'ADJ', 'irrational', 'n'], ['numbers', 'NOUN', 'number', 'n'], [',', 'PUNCT', ',', 'n'], ['geometrical', 'ADJ', 'geometrical', 'n'], ['magnitudes', 'NOUN', 'magnitude', 'n'], [',', 'PUNCT', ',', 'n'], ['etc', 'X', 'etc', 'n'], ['.', 'X', '.', 'n'], [',', 'PUNCT', ',', 'n'], ['to', 'AUX', 'to', 'n'], ['all', 'DET', 'all', 'n'], ['be', 'AUX', 'be', 'n'], ['treated', 'VERB', 'treat', 'n'], ['as', 'ADP', 'as', 'n'], ['\"', 'PUNCT', '\"', 'n'], ['algebraic', 'ADJ', 'algebraic', 'n'], ['objects', 'NOUN', 'object', 'n'], ['\"', 'PUNCT', '\"', 'n'], ['.', 'PUNCT', '.', 'n'], ['It', 'PRON', 'it', 'n'], ['gave', 'VERB', 'give', 'n'], ['mathematics', 'NOUN', 'mathematic', 'n'], ['a', 'DET', 'a', 'n'], ['whole', 'ADJ', 'whole', 'n'], ['new', 'ADJ', 'new', 'n'], ['\\n', 'SPACE', '\\n', 'n'], ['development', 'NOUN', 'development', 'n'], ['path', 'NOUN', 'path', 'n'], ['so', 'ADV', 'so', 'n'], ['much', 'ADV', 'much', 'n'], ['broader', 'ADJ', 'broad', 'n'], ['in', 'ADP', 'in', 'n'], ['concept', 'NOUN', 'concept', 'n'], ['to', 'ADP', 'to', 'n'], ['that', 'DET', 'that', 'n'], ['which', 'DET', 'which', 'n'], ['had', 'AUX', 'have', 'n'], ['existed', 'VERB', 'exist', 'n'], ['before', 'ADV', 'before', 'n'], [',', 'PUNCT', ',', 'n'], ['and', 'CCONJ', 'and', 'n'], ['provided', 'VERB', 'provide', 'n'], ['a', 'DET', 'a', 'n'], ['vehicle', 'NOUN', 'vehicle', 'n'], ['for', 'ADP', 'for', 'n'], ['future', 'ADJ', 'future', 'n'], ['development', 'NOUN', 'development', 'n'], ['of', 'ADP', 'of', 'n'], ['the', 'DET', 'the', 'n'], ['\\n', 'SPACE', '\\n', 'n'], ['subject', 'NOUN', 'subject', 'n'], ['.', 'PUNCT', '.', 'n'], ['Another', 'DET', 'another', 'n'], ['important', 'ADJ', 'important', 'n'], ['aspect', 'NOUN', 'aspect', 'n'], ['of', 'ADP', 'of', 'n'], ['the', 'DET', 'the', 'n'], ['introduction', 'NOUN', 'introduction', 'n'], ['of', 'ADP', 'of', 'n'], ['algebraic', 'ADJ', 'algebraic', 'n'], ['ideas', 'NOUN', 'idea', 'n'], ['was', 'AUX', 'be', 'n'], ['that', 'SCONJ', 'that', 'n'], ['it', 'PRON', 'it', 'n'], ['allowed', 'VERB', 'allow', 'n'], ['mathematics', 'NOUN', 'mathematic', 'n'], ['to', 'PART', 'to', 'n'], ['be', 'AUX', 'be', 'n'], ['applied', 'VERB', 'apply', 'n'], ['to', 'ADP', 'to', 'n'], ['itself', 'PRON', 'itself', 'n'], ['in', 'ADP', 'in', 'n'], ['a', 'DET', 'a', 'n'], ['\\n', 'SPACE', '\\n', 'n'], ['way', 'NOUN', 'way', 'n'], ['which', 'DET', 'which', 'n'], ['had', 'AUX', 'have', 'n'], ['not', 'PART', 'not', 'n'], ['happened', 'VERB', 'happen', 'n'], ['before', 'ADV', 'before', 'n'], ['.', 'PUNCT', '.', 'n'], ['\\n', 'SPACE', '\\n', 'n']]\n"
     ]
    }
   ],
   "source": [
    "#instantiating English module\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#creating doc object containing our token features\n",
    "doc = nlp(english_text)\n",
    "\n",
    "#Creating and updating our list of tokens using list comprehension \n",
    "tokens = [[token.text,token.pos_,token.lemma_,\"n\"] for token in doc]\n",
    "print(tokens)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123df055",
   "metadata": {},
   "source": [
    "# Lemmatization arabic text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f80464c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ربما', 'PROPN', 'ربما'], ['كانت', 'PROPN', 'كانت'], ['أحد', 'PROPN', 'أحد'], ['أهم', 'PROPN', 'أهم'], ['التطورات', 'VERB', 'التطورات'], ['التي', 'PROPN', 'التي'], ['قامت', 'VERB', 'قامت'], ['بها', 'NOUN', 'بها'], ['الرياضيات', 'ADJ', 'الرياضيات'], ['العربية', 'NOUN', 'العربية'], ['التي', 'NOUN', 'التي'], ['بدأت', 'VERB', 'بدأت'], ['في', 'ADP', 'في'], ['هذا', 'ADJ', 'هذا'], ['الوقت', 'NOUN', 'الوقت'], ['بعمل', 'PROPN', 'بعمل'], ['الخوارزمي', 'VERB', 'الخوارزمي'], ['و', 'PROPN', 'و'], ['هي', 'PROPN', 'هي'], ['بدايات', 'PROPN', 'بدايات'], ['الجبر', 'PROPN', 'الجبر'], ['،', 'PROPN', '،'], ['و', 'PROPN', 'و'], ['من', 'PROPN', 'من'], ['المهم', 'NOUN', 'المهم'], ['فهم', 'PROPN', 'فهم'], ['كيف', 'PROPN', 'كيف'], ['كانت', 'PROPN', 'كانت'], ['هذه', 'PROPN', 'هذه'], ['الفكرة', 'PROPN', 'الفكرة'], ['الجديدة', 'PROPN', 'الجديدة'], ['مهمة', 'PROPN', 'مهمة'], ['،', 'PROPN', '،'], ['فقد', 'PROPN', 'فقد'], ['كانت', 'PROPN', 'كانت'], ['خطوة', 'PROPN', 'خطوة'], ['ثورية', 'PROPN', 'ثورية'], ['بعيدا', 'VERB', 'بعيدا'], ['عن', 'PROPN', 'عن'], ['المفهوم', 'PROPN', 'المفهوم'], ['اليوناني', 'PROPN', 'اليوناني'], ['للرياضيات', 'PROPN', 'للرياضيات'], ['التي', 'PROPN', 'التي'], ['هي', 'PROPN', 'هي'], ['في', 'INTJ', 'في'], ['جوهرها', 'PROPN', 'جوهرها'], ['هندسة', 'PROPN', 'هندسة'], ['،', 'PROPN', '،'], ['الجبر', 'PROPN', 'الجبر'], ['كان', 'PROPN', 'كان'], ['نظرية', 'PROPN', 'نظرية'], ['موحدة', 'PROPN', 'موحدة'], ['تتيح', 'PROPN', 'تتيح'], ['الأعداد', 'PROPN', 'الأعداد'], ['الكسرية', 'NOUN', 'الكسرية'], ['و', 'PROPN', 'و'], ['الأعداد', 'NOUN', 'الأعداد'], ['اللا', 'NOUN', 'اللا'], ['كسرية', 'VERB', 'كسرية'], ['،', 'PROPN', '،'], ['و', 'PROPN', 'و'], ['قدم', 'PROPN', 'قدم'], ['وسيلة', 'NOUN', 'وسيلة'], ['للتنمية', 'ADJ', 'للتنمية'], ['في', 'ADP', 'في'], ['هذا', 'PROPN', 'هذا'], ['الموضوع', 'NOUN', 'الموضوع'], ['مستقبلا', 'PROPN', 'مستقبلا'], ['.', 'PUNCT', '.'], ['و', 'PRON', 'و'], ['جانب', 'PROPN', 'جانب'], ['آخر', 'NOUN', 'آخر'], ['مهم', 'NOUN', 'مهم'], ['لإدخال', 'NOUN', 'لإدخال'], ['أفكار', 'NOUN', 'أفكار'], ['الجبر', 'VERB', 'الجبر'], ['و', 'PROPN', 'و'], ['هو', 'PROPN', 'هو'], ['أنه', 'PROPN', 'أنه'], ['سمح', 'PROPN', 'سمح'], ['بتطبيق', 'PROPN', 'بتطبيق'], ['الرياضيات', 'PROPN', 'الرياضيات'], ['على', 'PROPN', 'على'], ['نفسها', 'PROPN', 'نفسها'], ['بطريقة', 'PROPN', 'بطريقة'], ['لم', 'PROPN', 'لم'], ['تحدث', 'PROPN', 'تحدث'], ['من', 'DET', 'من'], ['قبل', 'NOUN', 'قبل']]\n"
     ]
    }
   ],
   "source": [
    "#instantiating English module\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#creating doc object containing our token features\n",
    "doc = nlp(arabic_text)\n",
    "\n",
    "#Creating and updating our list of tokens using list comprehension \n",
    "tokens = [[token.text,token.pos_,token.lemma_,\"n\"] for token in doc]\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dae847",
   "metadata": {},
   "source": [
    "# Removing Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af4220",
   "metadata": {},
   "source": [
    "While working with textual data, we encounter many data instances which aren't of much use for our analysis as they do not add any meaning/relevance to our data. These can be pronouns (like I, you, etc.) or words like are , is , was , etc.\n",
    "\n",
    "These words are called Stop words. We can use the built in STOP_WORDS from spaCy for filtering our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e41ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'what', 'me', 'mine', 'namely', 'their', 'although', 'full', '‘re', 'third', 'wherever', 'empty', 'above', 'put', 'others', 'wherein', 'is', 'when', 'beforehand', 'n‘t', 'against', 'except', 'first', 'nobody', 'around', 'has', 'are', 'afterwards', 'which', 'if', 'had', 'indeed', 'becoming', 'none', 'nowhere', 'alone', 'anything', 'formerly', 'take', 'very', 'those', 'a', 'rather', \"'re\", 'further', 'our', \"'ll\", 'nine', 'fifteen', 'than', 'bottom', 'give', 'along', 'how', 'though', 'serious', 'towards', 'of', '’m', 'either', 'noone', 'using', 'am', 'quite', 'among', 'no', 'various', 're', 'or', 'these', 'least', 'onto', 'while', 'two', 'whatever', 'any', \"'s\", 'seeming', 'ca', 'down', 'nothing', 'regarding', 'often', 'eight', 'anyhow', 'and', 'doing', 'about', 'nor', 'whole', \"'ve\", 'front', 'did', 'n’t', 'hence', 'itself', 'get', 'why', 'toward', 'once', 'yourselves', 'here', 'behind', 'almost', 'could', 'without', 'may', 'who', 'more', 'some', 'up', 'never', 'only', 'whereas', 'for', 'name', 'them', 'across', 'whom', 'call', 'via', 'somewhere', 'everything', 'that', 'somehow', 'anyone', 'can', 'mostly', 'own', 'it', 'also', 'many', 'i', 'out', 'together', 'must', 'do', 'from', 'herein', 'to', 'hereupon', 'because', 'whither', 'sixty', 'perhaps', 'several', 'being', 'besides', 'well', 'between', 'twenty', 'even', '‘d', 'under', \"'m\", 'seemed', 'still', 'elsewhere', 'throughout', 'fifty', 'thereby', 'hundred', 'yourself', 'were', 'upon', 'next', 'he', 'otherwise', 'moreover', 'ourselves', 'his', 'thereupon', 'eleven', 'see', 'few', 'him', 'latterly', 'show', 'each', 'was', 'there', 'through', 'whereafter', 'into', 'will', '’d', 'become', 'but', 'ours', 'does', 'used', 'at', 'thus', 'with', 'other', '’ll', 'after', 'neither', 'have', 'hereafter', 'since', 'already', 'something', 'myself', 'whoever', 'ten', 'less', 'us', 'make', 'himself', 'three', 'go', 'last', 'thereafter', 'been', 'its', 'whence', 'therefore', 'became', 'made', 'yet', 'whereby', 'former', 'over', '’s', 'too', 'herself', 'on', '‘m', 'part', 'whenever', 'due', 'be', 'as', 'my', 'same', 'four', 'one', 'please', 'twelve', 'this', 'an', 'move', 'beside', 'else', 'again', 'really', 'her', 'such', 'five', 'someone', 'they', 'amount', 'always', 'everyone', 'off', 'whereupon', 'nevertheless', 'she', \"n't\", 'you', '’re', 'by', 'cannot', 'in', 'anyway', 'themselves', 'so', 'another', 'top', 'keep', 'beyond', 'should', 'back', 'thru', 'where', 'until', 'done', '’ve', 'we', 'the', 'before', 'whose', 'six', 'meanwhile', 'seems', 'your', 'enough', 'amongst', 'within', 'yours', 'below', \"'d\", 'therein', 'latter', 'now', 'sometimes', 'just', '‘ll', 'both', 'seem', '‘s', 'side', 'might', 'during', 'however', 'sometime', '‘ve', 'not', 'unless', 'hereby', 'forty', 'every', 'then', 'would', 'becomes', 'much', 'per', 'anywhere', 'everywhere', 'thence', 'hers', 'say', 'ever', 'all', 'most', 'whether'}\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stop = STOP_WORDS\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05cd52",
   "metadata": {},
   "source": [
    "# Filter_english_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6dc58289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perhaps', 'one', 'of', 'the', 'most', 'significant', 'advances', 'made', 'by', 'Arabic', 'mathematics', 'began', 'at', 'this', 'time', 'with', 'the', 'work', 'of', 'al', '-', 'Khwarizmi', ',', 'namely', '\\n', 'the', 'beginnings', 'of', 'algebra', '.', 'It', 'is', 'important', 'to', 'understand', 'just', 'how', 'significant', 'this', 'new', 'idea', 'was', '.', 'It', 'was', 'a', 'revolutionary', 'move', 'away', 'from', '\\n', 'the', 'Greek', 'concept', 'of', 'mathematics', 'which', 'was', 'essentially', 'geometry', '.', 'Algebra', 'was', 'a', 'unifying', 'theory', 'which', 'allowed', 'rational', '\\n', 'numbers', ',', 'irrational', 'numbers', ',', 'geometrical', 'magnitudes', ',', 'etc', '.', ',', 'to', 'all', 'be', 'treated', 'as', '\"', 'algebraic', 'objects', '\"', '.', 'It', 'gave', 'mathematics', 'a', 'whole', 'new', '\\n', 'development', 'path', 'so', 'much', 'broader', 'in', 'concept', 'to', 'that', 'which', 'had', 'existed', 'before', ',', 'and', 'provided', 'a', 'vehicle', 'for', 'future', 'development', 'of', 'the', '\\n', 'subject', '.', 'Another', 'important', 'aspect', 'of', 'the', 'introduction', 'of', 'algebraic', 'ideas', 'was', 'that', 'it', 'allowed', 'mathematics', 'to', 'be', 'applied', 'to', 'itself', 'in', 'a', '\\n', 'way', 'which', 'had', 'not', 'happened', 'before', '.', '\\n']\n",
      "['significant', 'advances', 'Arabic', 'mathematics', 'began', 'time', 'work', 'al', '-', 'Khwarizmi', ',', '\\n', 'beginnings', 'algebra', '.', 'important', 'understand', 'significant', 'new', 'idea', '.', 'revolutionary', 'away', '\\n', 'Greek', 'concept', 'mathematics', 'essentially', 'geometry', '.', 'Algebra', 'unifying', 'theory', 'allowed', 'rational', '\\n', 'numbers', ',', 'irrational', 'numbers', ',', 'geometrical', 'magnitudes', ',', 'etc', '.', ',', 'treated', '\"', 'algebraic', 'objects', '\"', '.', 'gave', 'mathematics', 'new', '\\n', 'development', 'path', 'broader', 'concept', 'existed', ',', 'provided', 'vehicle', 'future', 'development', '\\n', 'subject', '.', 'important', 'aspect', 'introduction', 'algebraic', 'ideas', 'allowed', 'mathematics', 'applied', '\\n', 'way', 'happened', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "doce = nlp(english_text)\n",
    "\n",
    "#Creating and updating our list of tokens using list comprehension \n",
    "\n",
    "tokens = [token.text for token in doce]\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "#Creating and updating our list of filtered tokens using list comprehension \n",
    "\n",
    "filtered = [token.text for token in doce if token.is_stop == False]\n",
    "\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a44d673",
   "metadata": {},
   "source": [
    "# You can observe the differences between the two lists. Indeed, spaCy makes our work pretty easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63634b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de76af75",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc66a9",
   "metadata": {},
   "source": [
    "A word's part of speech defines the functionality of that word in the document. For example - in the text Robin is an astute programmer, \"Robin\" is a Proper Noun while \"astute\" is an Adjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8070d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Perhaps', 'ADV'], ['one', 'NUM'], ['of', 'ADP'], ['the', 'DET'], ['most', 'ADV'], ['significant', 'ADJ'], ['advances', 'NOUN'], ['made', 'VERB'], ['by', 'ADP'], ['Arabic', 'ADJ'], ['mathematics', 'NOUN'], ['began', 'VERB'], ['at', 'ADP'], ['this', 'DET'], ['time', 'NOUN'], ['with', 'ADP'], ['the', 'DET'], ['work', 'NOUN'], ['of', 'ADP'], ['al', 'PROPN'], ['-', 'PUNCT'], ['Khwarizmi', 'PROPN'], [',', 'PUNCT'], ['namely', 'ADV'], ['\\n', 'SPACE'], ['the', 'DET'], ['beginnings', 'NOUN'], ['of', 'ADP'], ['algebra', 'PROPN'], ['.', 'PUNCT'], ['It', 'PRON'], ['is', 'AUX'], ['important', 'ADJ'], ['to', 'PART'], ['understand', 'VERB'], ['just', 'ADV'], ['how', 'ADV'], ['significant', 'ADJ'], ['this', 'DET'], ['new', 'ADJ'], ['idea', 'NOUN'], ['was', 'AUX'], ['.', 'PUNCT'], ['It', 'PRON'], ['was', 'AUX'], ['a', 'DET'], ['revolutionary', 'ADJ'], ['move', 'NOUN'], ['away', 'ADV'], ['from', 'ADP'], ['\\n', 'SPACE'], ['the', 'DET'], ['Greek', 'ADJ'], ['concept', 'NOUN'], ['of', 'ADP'], ['mathematics', 'NOUN'], ['which', 'DET'], ['was', 'VERB'], ['essentially', 'ADV'], ['geometry', 'NOUN'], ['.', 'PUNCT'], ['Algebra', 'PROPN'], ['was', 'AUX'], ['a', 'DET'], ['unifying', 'ADJ'], ['theory', 'NOUN'], ['which', 'DET'], ['allowed', 'VERB'], ['rational', 'ADJ'], ['\\n', 'SPACE'], ['numbers', 'NOUN'], [',', 'PUNCT'], ['irrational', 'ADJ'], ['numbers', 'NOUN'], [',', 'PUNCT'], ['geometrical', 'ADJ'], ['magnitudes', 'NOUN'], [',', 'PUNCT'], ['etc', 'X'], ['.', 'X'], [',', 'PUNCT'], ['to', 'AUX'], ['all', 'DET'], ['be', 'AUX'], ['treated', 'VERB'], ['as', 'ADP'], ['\"', 'PUNCT'], ['algebraic', 'ADJ'], ['objects', 'NOUN'], ['\"', 'PUNCT'], ['.', 'PUNCT'], ['It', 'PRON'], ['gave', 'VERB'], ['mathematics', 'NOUN'], ['a', 'DET'], ['whole', 'ADJ'], ['new', 'ADJ'], ['\\n', 'SPACE'], ['development', 'NOUN'], ['path', 'NOUN'], ['so', 'ADV'], ['much', 'ADV'], ['broader', 'ADJ'], ['in', 'ADP'], ['concept', 'NOUN'], ['to', 'ADP'], ['that', 'DET'], ['which', 'DET'], ['had', 'AUX'], ['existed', 'VERB'], ['before', 'ADV'], [',', 'PUNCT'], ['and', 'CCONJ'], ['provided', 'VERB'], ['a', 'DET'], ['vehicle', 'NOUN'], ['for', 'ADP'], ['future', 'ADJ'], ['development', 'NOUN'], ['of', 'ADP'], ['the', 'DET'], ['\\n', 'SPACE'], ['subject', 'NOUN'], ['.', 'PUNCT'], ['Another', 'DET'], ['important', 'ADJ'], ['aspect', 'NOUN'], ['of', 'ADP'], ['the', 'DET'], ['introduction', 'NOUN'], ['of', 'ADP'], ['algebraic', 'ADJ'], ['ideas', 'NOUN'], ['was', 'AUX'], ['that', 'SCONJ'], ['it', 'PRON'], ['allowed', 'VERB'], ['mathematics', 'NOUN'], ['to', 'PART'], ['be', 'AUX'], ['applied', 'VERB'], ['to', 'ADP'], ['itself', 'PRON'], ['in', 'ADP'], ['a', 'DET'], ['\\n', 'SPACE'], ['way', 'NOUN'], ['which', 'DET'], ['had', 'AUX'], ['not', 'PART'], ['happened', 'VERB'], ['before', 'ADV'], ['.', 'PUNCT'], ['\\n', 'SPACE']]\n"
     ]
    }
   ],
   "source": [
    "#Creating doc object\n",
    "doc = nlp(english_text)\n",
    "\n",
    "#Extracting POS\n",
    "pos = [[token.text,token.pos_] for token in doc]\n",
    "print (pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca4490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a54861fc",
   "metadata": {},
   "source": [
    "# Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1e127",
   "metadata": {},
   "source": [
    " Entity recognition is a text preprocessing technique that identifies word-describing elements like places, people, organizations, and languages within our input text.\n",
    "We will make use of \".ents\" attribute of our doc object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65b84b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Arabic mathematics, 'NORP', 381), (al-Khwarizmi, 'GPE', 384), (Greek, 'NORP', 381)]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "#creating doc object\n",
    "eng_doc= nlp(english_text)\n",
    "\n",
    "\n",
    "#extracting entities \n",
    "entities=[(i, i.label_, i.label) for i in eng_doc.ents]\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714ed87",
   "metadata": {},
   "source": [
    "#  Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f29c8",
   "metadata": {},
   "source": [
    "Chunking is the process of extracting noun phrases from the text. spaCy can identify noun phrases (or noun chunks), as well. You can think of noun chunks as a noun plus the words describing the noun. It’s also possible to identify and extract the base-noun of a given chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5751fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most significant advances advances pobj of\n",
      "Arabic mathematics mathematics pobj by\n",
      "this time time pobj at\n",
      "the work work pobj with\n",
      "al-Khwarizmi Khwarizmi pobj of\n",
      "the beginnings beginnings dobj \n",
      "\n",
      "algebra algebra pobj of\n",
      "It It nsubj is\n",
      "this new idea idea nsubj was\n",
      "It It nsubj was\n",
      "a revolutionary move move attr was\n",
      "the Greek concept concept attr was\n",
      "mathematics mathematics pobj of\n",
      "essentially geometry geometry attr was\n",
      "Algebra Algebra nsubj was\n",
      "a unifying theory theory attr was\n",
      "rational \n",
      "numbers numbers dobj allowed\n",
      "irrational numbers numbers conj numbers\n",
      "geometrical magnitudes magnitudes conj numbers\n",
      "\"algebraic objects objects pobj as\n",
      "It It nsubj gave\n",
      "mathematics mathematics dative gave\n",
      "a whole new \n",
      "development path path dobj gave\n",
      "concept concept pobj in\n",
      "a vehicle vehicle dobj provided\n",
      "future development development pobj for\n",
      "the \n",
      "subject subject pobj of\n",
      "Another important aspect aspect nsubj was\n",
      "the introduction introduction pobj of\n",
      "algebraic ideas ideas pobj of\n",
      "it it nsubj allowed\n",
      "mathematics mathematics nsubjpass applied\n",
      "itself itself pobj to\n",
      "a \n",
      "way way pobj in\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(english_text)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d3e1c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Great work]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "def filtered_chunks(doc, pattern):\n",
    "  for chunk in doc.noun_chunks:\n",
    "    signature = ''.join(['<%s>' % w.tag_ for w in chunk])\n",
    "    if pattern.match(signature) is not None:\n",
    "      yield chunk\n",
    " \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u'Great work!')\n",
    "pattern = re.compile(r'(<JJ>)*(<NN>|<NNS>|<NNP>)+')\n",
    "\n",
    "print(list(filtered_chunks(doc, pattern)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e788f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f57fed5b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0e935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45eaa3fc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138883a9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca571230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c50862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9fc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b93ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211d112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
