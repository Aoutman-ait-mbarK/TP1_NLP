{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e5d2c1",
   "metadata": {},
   "source": [
    "# TP1 NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49bbca",
   "metadata": {},
   "source": [
    "Natural Language Toolkit\n",
    "The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd052435",
   "metadata": {},
   "outputs": [],
   "source": [
    "## install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9d0b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01037542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695509e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    " \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize,PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea8a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "arabic_text=\"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي و هي بدايات الجبر، و من المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن المفهوم اليوناني للرياضيات التي هي في جوهرها هندسة، الجبر كان نظرية موحدة تتيح الأعداد الكسرية و الأعداد اللا كسرية، و قدم وسيلة للتنمية في هذا الموضوع مستقبلا. و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل\"\"\"\n",
    "\n",
    "english_text= \"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely \n",
    "the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from \n",
    "the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational \n",
    "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new \n",
    "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the \n",
    "subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a \n",
    "way which had not happened before.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485aa1b",
   "metadata": {},
   "source": [
    "# ***Tokenize text by Syllable***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "531cdb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Per', 'ha', 'ps o', 'ne ', 'o', 'f t', 'he ', 'mos', 't ', 'si', 'gni', 'fi', 'can', 't a', 'dvan', 'ce', 's ', 'ma', 'de ', 'by A', 'ra', 'bi', 'c ', 'mat', 'he', 'ma', 'ti', 'cs ', 'be', 'ga', 'n a', 't t', 'hi', 's ', 'ti', 'me ', 'wit', 'h t', 'he ', 'wor', 'k o', 'f al', '-', 'Khwa', 'ri', 'zmi', ',', ' ', 'na', 'me', 'ly ', '\\nt', 'he ', 'be', 'gin', 'nin', 'gs o', 'f al', 'ge', 'bra', '.', ' I', 't i', 's im', 'por', 'tan', 't ', 'to ', 'un', 'ders', 'tan', 'd ', 'jus', 't ', 'ho', 'w ', 'si', 'gni', 'fi', 'can', 't t', 'hi', 's ', 'ne', 'w i', 'dea', ' ', 'was', '.', ' I', 't ', 'wa', 's a', ' ', 're', 'vo', 'lu', 'tio', 'na', 'ry ', 'mo', 've ', 'a', 'way', ' ', 'fro', 'm \\nt', 'he ', 'Gree', 'k ', 'con', 'cep', 't o', 'f ', 'mat', 'he', 'ma', 'ti', 'cs w', 'hic', 'h ', 'wa', 's es', 'sen', 'tial', 'ly ', 'geo', 'me', 'try', '.', ' Al', 'ge', 'bra ', 'wa', 's a', ' ', 'u', 'ni', 'fyin', 'g t', 'heo', 'ry w', 'hic', 'h al', 'lo', 'we', 'd ', 'ra', 'tio', 'na', 'l \\n', 'num', 'bers', ',', ' ir', 'ra', 'tio', 'na', 'l ', 'num', 'bers', ',', ' ', 'geo', 'me', 'tri', 'ca', 'l ', 'ma', 'gni', 'tu', 'des', ',', ' etc', '.', '', ',', ' ', 'to ', 'al', 'l ', 'be ', 'trea', 'te', 'd a', 's ', '\"', 'al', 'ge', 'brai', 'c ob', 'jects', '\"', '', '.', ' I', 't ', 'ga', 've ', 'mat', 'he', 'ma', 'ti', 'cs a', ' w', 'ho', 'le ', 'ne', 'w \\n', 'de', 've', 'lo', 'pmen', 't ', 'pat', 'h ', 'so ', 'muc', 'h ', 'broa', 'de', 'r i', 'n ', 'con', 'cep', 't ', 'to t', 'ha', 't w', 'hic', 'h ', 'ha', 'd e', 'xis', 'te', 'd ', 'be', 'fo', 're', ',', ' an', 'd ', 'pro', 'vi', 'de', 'd a', ' ', 've', 'hi', 'cle ', 'fo', 'r ', 'fu', 'tu', 're ', 'de', 've', 'lo', 'pmen', 't o', 'f t', 'he ', '\\n', 'sub', 'ject', '.', ' A', 'not', 'he', 'r im', 'por', 'tan', 't as', 'pec', 't o', 'f t', 'he ', 'in', 'tro', 'duc', 'tio', 'n o', 'f al', 'ge', 'brai', 'c i', 'dea', 's ', 'wa', 's t', 'ha', 't i', 't al', 'lo', 'we', 'd ', 'mat', 'he', 'ma', 'ti', 'cs ', 'to ', 'be ', 'ap', 'plie', 'd ', 'to ', 'i', 'tsel', 'f i', 'n a', ' ', '\\n', 'way', ' w', 'hic', 'h ', 'ha', 'd ', 'no', 't ', 'hap', 'pe', 'ne', 'd ', 'be', 'fo', 're', '.', '\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: ' '\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: '\n",
      "'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tk = nltk.SyllableTokenizer()\n",
    "print(tk.tokenize(english_text))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992dc601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['رب', 'م', 'ا', ' ', 'ك', 'ا', 'ن', 'ت', ' ', 'أ', 'ح', 'د', ' ', 'أ', 'ه', 'م', ' ', 'ا', 'ل', 'ت', 'ط', 'و', 'ر', 'ا', 'ت', ' ', 'ا', 'ل', 'ت', 'ي', ' ', 'ق', 'ا', 'م', 'ت', ' ', 'ب', 'ه', 'ا', ' ', 'ا', 'ل', 'ر', 'ي', 'ا', 'ض', 'ي', 'ا', 'ت', ' ', 'ا', 'ل', 'ع', 'ر', 'ب', 'ي', 'ة', ' ', 'ا', 'ل', 'ت', 'ي', ' ', 'ب', 'د', 'أ', 'ت', ' ', 'ف', 'ي', ' ', 'ه', 'ذ', 'ا', ' ', 'ا', 'ل', 'و', 'ق', 'ت', ' ', 'ب', 'ع', 'م', 'ل', ' ', 'ا', 'ل', 'خ', 'و', 'ا', 'ر', 'ز', 'م', 'ي', ' ', 'و', ' ', 'ه', 'ي', ' ', 'ب', 'د', 'ا', 'ي', 'ا', 'ت', ' ', 'ا', 'ل', 'ج', 'ب', 'ر', '،', ' ', 'و', ' ', 'م', 'ن', ' ', 'ا', 'ل', 'م', 'ه', 'م', ' ', 'ف', 'ه', 'م', ' ', 'ك', 'ي', 'ف', ' ', 'ك', 'ا', 'ن', 'ت', ' ', 'ه', 'ذ', 'ه', ' ', 'ا', 'ل', 'ف', 'ك', 'ر', 'ة', ' ', 'ا', 'ل', 'ج', 'د', 'ي', 'د', 'ة', ' ', 'م', 'ه', 'م', 'ة', '،', ' ', 'ف', 'ق', 'د', ' ', 'ك', 'ا', 'ن', 'ت', ' ', 'خ', 'ط', 'و', 'ة', ' ', 'ث', 'و', 'ر', 'ي', 'ة', ' ', 'ب', 'ع', 'ي', 'د', 'ا', ' ', 'ع', 'ن', ' ', 'ا', 'ل', 'م', 'ف', 'ه', 'و', 'م', ' ', 'ا', 'ل', 'ي', 'و', 'ن', 'ا', 'ن', 'ي', ' ', 'ل', 'ل', 'ر', 'ي', 'ا', 'ض', 'ي', 'ا', 'ت', ' ', 'ا', 'ل', 'ت', 'ي', ' ', 'ه', 'ي', ' ', 'ف', 'ي', ' ', 'ج', 'و', 'ه', 'ر', 'ه', 'ا', ' ', 'ه', 'ن', 'د', 'س', 'ة', '،', ' ', 'ا', 'ل', 'ج', 'ب', 'ر', ' ', 'ك', 'ا', 'ن', ' ', 'ن', 'ظ', 'ر', 'ي', 'ة', ' ', 'م', 'و', 'ح', 'د', 'ة', ' ', 'ت', 'ت', 'ي', 'ح', ' ', 'ا', 'ل', 'أ', 'ع', 'د', 'ا', 'د', ' ', 'ا', 'ل', 'ك', 'س', 'ر', 'ي', 'ة', ' ', 'و', ' ', 'ا', 'ل', 'أ', 'ع', 'د', 'ا', 'د', ' ', 'ا', 'ل', 'ل', 'ا', ' ', 'ك', 'س', 'ر', 'ي', 'ة', '،', ' ', 'و', ' ', 'ق', 'د', 'م', ' ', 'و', 'س', 'ي', 'ل', 'ة', ' ', 'ل', 'ل', 'ت', 'ن', 'م', 'ي', 'ة', ' ', 'ف', 'ي', ' ', 'ه', 'ذ', 'ا', ' ', 'ا', 'ل', 'م', 'و', 'ض', 'و', 'ع', ' ', 'م', 'س', 'ت', 'ق', 'ب', 'ل', 'ا', '.', ' و', ' ', 'ج', 'ا', 'ن', 'ب', ' ', 'آ', 'خ', 'ر', ' ', 'م', 'ه', 'م', ' ', 'ل', 'إ', 'د', 'خ', 'ا', 'ل', ' ', 'أ', 'ف', 'ك', 'ا', 'ر', ' ', 'ا', 'ل', 'ج', 'ب', 'ر', ' ', 'و', ' ', 'ه', 'و', ' ', 'أ', 'ن', 'ه', ' ', 'س', 'م', 'ح', ' ', 'ب', 'ت', 'ط', 'ب', 'ي', 'ق', ' ', 'ا', 'ل', 'ر', 'ي', 'ا', 'ض', 'ي', 'ا', 'ت', ' ', 'ع', 'ل', 'ى', ' ', 'ن', 'ف', 'س', 'ه', 'ا', ' ', 'ب', 'ط', 'ر', 'ي', 'ق', 'ة', ' ', 'ل', 'م', ' ', 'ت', 'ح', 'د', 'ث', ' ', 'م', 'ن', ' ', 'ق', 'ب', 'ل']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ر'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ب'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'م'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ا'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ك'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ن'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ت'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'أ'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ح'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'د'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ه'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ل'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ط'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'و'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ي'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ق'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ض'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ع'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ة'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ف'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ذ'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'خ'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ز'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ج'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: '،'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ث'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'س'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ظ'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'آ'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'إ'\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: 'ى'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tk = nltk.SyllableTokenizer()\n",
    "print(tk.tokenize(arabic_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c787abe1",
   "metadata": {},
   "source": [
    "# tokenize text by word"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32d311d8",
   "metadata": {},
   "source": [
    "tokenize english text by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f19e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perhaps\n",
      "one\n",
      "of\n",
      "the\n",
      "most\n",
      "significant\n",
      "advances\n",
      "made\n",
      "by\n",
      "Arabic\n",
      "mathematics\n",
      "began\n",
      "at\n",
      "this\n",
      "time\n",
      "with\n",
      "the\n",
      "work\n",
      "of\n",
      "al-Khwarizmi\n",
      ",\n",
      "namely\n",
      "the\n",
      "beginnings\n",
      "of\n",
      "algebra\n",
      ".\n",
      "It\n",
      "is\n",
      "important\n",
      "to\n",
      "understand\n",
      "just\n",
      "how\n",
      "significant\n",
      "this\n",
      "new\n",
      "idea\n",
      "was\n",
      ".\n",
      "It\n",
      "was\n",
      "a\n",
      "revolutionary\n",
      "move\n",
      "away\n",
      "from\n",
      "the\n",
      "Greek\n",
      "concept\n",
      "of\n",
      "mathematics\n",
      "which\n",
      "was\n",
      "essentially\n",
      "geometry\n",
      ".\n",
      "Algebra\n",
      "was\n",
      "a\n",
      "unifying\n",
      "theory\n",
      "which\n",
      "allowed\n",
      "rational\n",
      "numbers\n",
      ",\n",
      "irrational\n",
      "numbers\n",
      ",\n",
      "geometrical\n",
      "magnitudes\n",
      ",\n",
      "etc.\n",
      ",\n",
      "to\n",
      "all\n",
      "be\n",
      "treated\n",
      "as\n",
      "``\n",
      "algebraic\n",
      "objects\n",
      "''\n",
      ".\n",
      "It\n",
      "gave\n",
      "mathematics\n",
      "a\n",
      "whole\n",
      "new\n",
      "development\n",
      "path\n",
      "so\n",
      "much\n",
      "broader\n",
      "in\n",
      "concept\n",
      "to\n",
      "that\n",
      "which\n",
      "had\n",
      "existed\n",
      "before\n",
      ",\n",
      "and\n",
      "provided\n",
      "a\n",
      "vehicle\n",
      "for\n",
      "future\n",
      "development\n",
      "of\n",
      "the\n",
      "subject\n",
      ".\n",
      "Another\n",
      "important\n",
      "aspect\n",
      "of\n",
      "the\n",
      "introduction\n",
      "of\n",
      "algebraic\n",
      "ideas\n",
      "was\n",
      "that\n",
      "it\n",
      "allowed\n",
      "mathematics\n",
      "to\n",
      "be\n",
      "applied\n",
      "to\n",
      "itself\n",
      "in\n",
      "a\n",
      "way\n",
      "which\n",
      "had\n",
      "not\n",
      "happened\n",
      "before\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize,PunktSentenceTokenizer\n",
    "english_text= \"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely \n",
    "the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from \n",
    "the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational \n",
    "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new \n",
    "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the \n",
    "subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a \n",
    "way which had not happened before.\n",
    "\"\"\"\n",
    "for i in range(len(word_tokenize((english_text)))) :\n",
    "   print(word_tokenize((english_text))[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097f86c",
   "metadata": {},
   "source": [
    "# tokenize arabic text by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45c41d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ربما\n",
      "كانت\n",
      "أحد\n",
      "أهم\n",
      "التطورات\n",
      "التي\n",
      "قامت\n",
      "بها\n",
      "الرياضيات\n",
      "العربية\n",
      "التي\n",
      "بدأت\n",
      "في\n",
      "هذا\n",
      "الوقت\n",
      "بعمل\n",
      "الخوارزمي\n",
      "و\n",
      "هي\n",
      "بدايات\n",
      "الجبر،\n",
      "و\n",
      "من\n",
      "المهم\n",
      "فهم\n",
      "كيف\n",
      "كانت\n",
      "هذه\n",
      "الفكرة\n",
      "الجديدة\n",
      "مهمة،\n",
      "فقد\n",
      "كانت\n",
      "خطوة\n",
      "ثورية\n",
      "بعيدا\n",
      "عن\n",
      "المفهوم\n",
      "اليوناني\n",
      "للرياضيات\n",
      "التي\n",
      "هي\n",
      "في\n",
      "جوهرها\n",
      "هندسة،\n",
      "الجبر\n",
      "كان\n",
      "نظرية\n",
      "موحدة\n",
      "تتيح\n",
      "الأعداد\n",
      "الكسرية\n",
      "و\n",
      "الأعداد\n",
      "اللا\n",
      "كسرية،\n",
      "و\n",
      "قدم\n",
      "وسيلة\n",
      "للتنمية\n",
      "في\n",
      "هذا\n",
      "الموضوع\n",
      "مستقبلا\n",
      ".\n",
      "و\n",
      "جانب\n",
      "آخر\n",
      "مهم\n",
      "لإدخال\n",
      "أفكار\n",
      "الجبر\n",
      "و\n",
      "هو\n",
      "أنه\n",
      "سمح\n",
      "بتطبيق\n",
      "الرياضيات\n",
      "على\n",
      "نفسها\n",
      "بطريقة\n",
      "لم\n",
      "تحدث\n",
      "من\n",
      "قبل\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize,PunktSentenceTokenizer\n",
    "\n",
    "arabic_text=\"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي و هي بدايات الجبر، و من المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن المفهوم اليوناني للرياضيات التي هي في جوهرها هندسة، الجبر كان نظرية موحدة تتيح الأعداد الكسرية و الأعداد اللا كسرية، و قدم وسيلة للتنمية في هذا الموضوع مستقبلا. و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل\"\"\"\n",
    "\n",
    "\n",
    "for i in range(len(word_tokenize((arabic_text)))) :\n",
    "   print(word_tokenize((arabic_text))[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bbc61",
   "metadata": {},
   "source": [
    "# Sentence Tokenizing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d7219fe",
   "metadata": {},
   "source": [
    "----------------------tokenize english text by sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68edd075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely \n",
      "the beginnings of algebra.\n",
      "\n",
      "It is important to understand just how significant this new idea was.\n",
      "\n",
      "It was a revolutionary move away from \n",
      "the Greek concept of mathematics which was essentially geometry.\n",
      "\n",
      "Algebra was a unifying theory which allowed rational \n",
      "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\".\n",
      "\n",
      "It gave mathematics a whole new \n",
      "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the \n",
      "subject.\n",
      "\n",
      "Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a \n",
      "way which had not happened before.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sent_tokenize(english_text))) :\n",
    "     print(sent_tokenize(english_text)[i])\n",
    "     print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc40360c",
   "metadata": {},
   "source": [
    "----------------------tokenize arabic text by sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c95efa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي و هي بدايات الجبر، و من المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن المفهوم اليوناني للرياضيات التي هي في جوهرها هندسة، الجبر كان نظرية موحدة تتيح الأعداد الكسرية و الأعداد اللا كسرية، و قدم وسيلة للتنمية في هذا الموضوع مستقبلا.\n",
      "\n",
      "و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sent_tokenize(arabic_text))) :\n",
    "     print(sent_tokenize(arabic_text)[i])\n",
    "     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae9f31",
   "metadata": {},
   "source": [
    "# Filtering  Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dc58289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b014646b",
   "metadata": {},
   "source": [
    "NLTK has by default a bunch of words that it considers to be stop words. It can be accessed via the NLTK corpus with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8070d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01928199",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cbfd6",
   "metadata": {},
   "source": [
    " Example to incorporate the stop_words set to remove the stop words from a given text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8569057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfiltered:  ['Perhaps', 'one', 'of', 'the', 'most', 'significant', 'advances', 'made', 'by', 'Arabic', 'mathematics', 'began', 'at', 'this', 'time', 'with', 'the', 'work', 'of', 'al-Khwarizmi', ',', 'namely', 'the', 'beginnings', 'of', 'algebra', '.', 'It', 'is', 'important', 'to', 'understand', 'just', 'how', 'significant', 'this', 'new', 'idea', 'was', '.', 'It', 'was', 'a', 'revolutionary', 'move', 'away', 'from', 'the', 'Greek', 'concept', 'of', 'mathematics', 'which', 'was', 'essentially', 'geometry', '.', 'Algebra', 'was', 'a', 'unifying', 'theory', 'which', 'allowed', 'rational', 'numbers', ',', 'irrational', 'numbers', ',', 'geometrical', 'magnitudes', ',', 'etc.', ',', 'to', 'all', 'be', 'treated', 'as', '``', 'algebraic', 'objects', \"''\", '.', 'It', 'gave', 'mathematics', 'a', 'whole', 'new', 'development', 'path', 'so', 'much', 'broader', 'in', 'concept', 'to', 'that', 'which', 'had', 'existed', 'before', ',', 'and', 'provided', 'a', 'vehicle', 'for', 'future', 'development', 'of', 'the', 'subject', '.', 'Another', 'important', 'aspect', 'of', 'the', 'introduction', 'of', 'algebraic', 'ideas', 'was', 'that', 'it', 'allowed', 'mathematics', 'to', 'be', 'applied', 'to', 'itself', 'in', 'a', 'way', 'which', 'had', 'not', 'happened', 'before', '.']\n",
      "Filtered:  ['Perhaps', 'one', 'significant', 'advances', 'made', 'Arabic', 'mathematics', 'began', 'time', 'work', 'al-Khwarizmi', ',', 'namely', 'beginnings', 'algebra', '.', 'It', 'important', 'understand', 'significant', 'new', 'idea', '.', 'It', 'revolutionary', 'move', 'away', 'Greek', 'concept', 'mathematics', 'essentially', 'geometry', '.', 'Algebra', 'unifying', 'theory', 'allowed', 'rational', 'numbers', ',', 'irrational', 'numbers', ',', 'geometrical', 'magnitudes', ',', 'etc.', ',', 'treated', '``', 'algebraic', 'objects', \"''\", '.', 'It', 'gave', 'mathematics', 'whole', 'new', 'development', 'path', 'much', 'broader', 'concept', 'existed', ',', 'provided', 'vehicle', 'future', 'development', 'subject', '.', 'Another', 'important', 'aspect', 'introduction', 'algebraic', 'ideas', 'allowed', 'mathematics', 'applied', 'way', 'happened', '.']\n"
     ]
    }
   ],
   "source": [
    "english_text= \"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely \n",
    "the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from \n",
    "the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational \n",
    "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new \n",
    "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the \n",
    "subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a \n",
    "way which had not happened before.\n",
    "\"\"\"\n",
    "words = nltk.word_tokenize(english_text)\n",
    "print(\"Unfiltered: \", words)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "cleaned = [word for word in words if word not in stopwords]\n",
    "print(\"Filtered: \", cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc63e3",
   "metadata": {},
   "source": [
    "# You can observe the differences between the two lists Unfiltered & Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca4490",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8c452",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e4d44",
   "metadata": {},
   "source": [
    "# Stemming  English Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de2e788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perhaps  :  perhap\n",
      "one  :  one\n",
      "of  :  of\n",
      "the  :  the\n",
      "most  :  most\n",
      "significant  :  signific\n",
      "advances  :  advanc\n",
      "made  :  made\n",
      "by  :  by\n",
      "Arabic  :  arab\n",
      "mathematics  :  mathemat\n",
      "began  :  began\n",
      "at  :  at\n",
      "this  :  thi\n",
      "time  :  time\n",
      "with  :  with\n",
      "the  :  the\n",
      "work  :  work\n",
      "of  :  of\n",
      "al-Khwarizmi  :  al-khwarizmi\n",
      ",  :  ,\n",
      "namely  :  name\n",
      "the  :  the\n",
      "beginnings  :  begin\n",
      "of  :  of\n",
      "algebra  :  algebra\n",
      ".  :  .\n",
      "It  :  it\n",
      "is  :  is\n",
      "important  :  import\n",
      "to  :  to\n",
      "understand  :  understand\n",
      "just  :  just\n",
      "how  :  how\n",
      "significant  :  signific\n",
      "this  :  thi\n",
      "new  :  new\n",
      "idea  :  idea\n",
      "was  :  wa\n",
      ".  :  .\n",
      "It  :  it\n",
      "was  :  wa\n",
      "a  :  a\n",
      "revolutionary  :  revolutionari\n",
      "move  :  move\n",
      "away  :  away\n",
      "from  :  from\n",
      "the  :  the\n",
      "Greek  :  greek\n",
      "concept  :  concept\n",
      "of  :  of\n",
      "mathematics  :  mathemat\n",
      "which  :  which\n",
      "was  :  wa\n",
      "essentially  :  essenti\n",
      "geometry  :  geometri\n",
      ".  :  .\n",
      "Algebra  :  algebra\n",
      "was  :  wa\n",
      "a  :  a\n",
      "unifying  :  unifi\n",
      "theory  :  theori\n",
      "which  :  which\n",
      "allowed  :  allow\n",
      "rational  :  ration\n",
      "numbers  :  number\n",
      ",  :  ,\n",
      "irrational  :  irrat\n",
      "numbers  :  number\n",
      ",  :  ,\n",
      "geometrical  :  geometr\n",
      "magnitudes  :  magnitud\n",
      ",  :  ,\n",
      "etc.  :  etc.\n",
      ",  :  ,\n",
      "to  :  to\n",
      "all  :  all\n",
      "be  :  be\n",
      "treated  :  treat\n",
      "as  :  as\n",
      "``  :  ``\n",
      "algebraic  :  algebra\n",
      "objects  :  object\n",
      "''  :  ''\n",
      ".  :  .\n",
      "It  :  it\n",
      "gave  :  gave\n",
      "mathematics  :  mathemat\n",
      "a  :  a\n",
      "whole  :  whole\n",
      "new  :  new\n",
      "development  :  develop\n",
      "path  :  path\n",
      "so  :  so\n",
      "much  :  much\n",
      "broader  :  broader\n",
      "in  :  in\n",
      "concept  :  concept\n",
      "to  :  to\n",
      "that  :  that\n",
      "which  :  which\n",
      "had  :  had\n",
      "existed  :  exist\n",
      "before  :  befor\n",
      ",  :  ,\n",
      "and  :  and\n",
      "provided  :  provid\n",
      "a  :  a\n",
      "vehicle  :  vehicl\n",
      "for  :  for\n",
      "future  :  futur\n",
      "development  :  develop\n",
      "of  :  of\n",
      "the  :  the\n",
      "subject  :  subject\n",
      ".  :  .\n",
      "Another  :  anoth\n",
      "important  :  import\n",
      "aspect  :  aspect\n",
      "of  :  of\n",
      "the  :  the\n",
      "introduction  :  introduct\n",
      "of  :  of\n",
      "algebraic  :  algebra\n",
      "ideas  :  idea\n",
      "was  :  wa\n",
      "that  :  that\n",
      "it  :  it\n",
      "allowed  :  allow\n",
      "mathematics  :  mathemat\n",
      "to  :  to\n",
      "be  :  be\n",
      "applied  :  appli\n",
      "to  :  to\n",
      "itself  :  itself\n",
      "in  :  in\n",
      "a  :  a\n",
      "way  :  way\n",
      "which  :  which\n",
      "had  :  had\n",
      "not  :  not\n",
      "happened  :  happen\n",
      "before  :  befor\n",
      ".  :  .\n"
     ]
    }
   ],
   "source": [
    "# importing modules\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "  \n",
    "ps = PorterStemmer()\n",
    "\n",
    "words = word_tokenize(english_text)\n",
    "  \n",
    "for w in words:\n",
    "    print(w, \" : \", ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57fed5b",
   "metadata": {},
   "source": [
    "# Stemming Arabic Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e0e935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ربما  :  ربما\n",
      "كانت  :  كانت\n",
      "أحد  :  أحد\n",
      "أهم  :  أهم\n",
      "التطورات  :  التطورات\n",
      "التي  :  التي\n",
      "قامت  :  قامت\n",
      "بها  :  بها\n",
      "الرياضيات  :  الرياضيات\n",
      "العربية  :  العربية\n",
      "التي  :  التي\n",
      "بدأت  :  بدأت\n",
      "في  :  في\n",
      "هذا  :  هذا\n",
      "الوقت  :  الوقت\n",
      "بعمل  :  بعمل\n",
      "الخوارزمي  :  الخوارزمي\n",
      "و  :  و\n",
      "هي  :  هي\n",
      "بدايات  :  بدايات\n",
      "الجبر،  :  الجبر،\n",
      "و  :  و\n",
      "من  :  من\n",
      "المهم  :  المهم\n",
      "فهم  :  فهم\n",
      "كيف  :  كيف\n",
      "كانت  :  كانت\n",
      "هذه  :  هذه\n",
      "الفكرة  :  الفكرة\n",
      "الجديدة  :  الجديدة\n",
      "مهمة،  :  مهمة،\n",
      "فقد  :  فقد\n",
      "كانت  :  كانت\n",
      "خطوة  :  خطوة\n",
      "ثورية  :  ثورية\n",
      "بعيدا  :  بعيدا\n",
      "عن  :  عن\n",
      "المفهوم  :  المفهوم\n",
      "اليوناني  :  اليوناني\n",
      "للرياضيات  :  للرياضيات\n",
      "التي  :  التي\n",
      "هي  :  هي\n",
      "في  :  في\n",
      "جوهرها  :  جوهرها\n",
      "هندسة،  :  هندسة،\n",
      "الجبر  :  الجبر\n",
      "كان  :  كان\n",
      "نظرية  :  نظرية\n",
      "موحدة  :  موحدة\n",
      "تتيح  :  تتيح\n",
      "الأعداد  :  الأعداد\n",
      "الكسرية  :  الكسرية\n",
      "و  :  و\n",
      "الأعداد  :  الأعداد\n",
      "اللا  :  اللا\n",
      "كسرية،  :  كسرية،\n",
      "و  :  و\n",
      "قدم  :  قدم\n",
      "وسيلة  :  وسيلة\n",
      "للتنمية  :  للتنمية\n",
      "في  :  في\n",
      "هذا  :  هذا\n",
      "الموضوع  :  الموضوع\n",
      "مستقبلا  :  مستقبلا\n",
      ".  :  .\n",
      "و  :  و\n",
      "جانب  :  جانب\n",
      "آخر  :  آخر\n",
      "مهم  :  مهم\n",
      "لإدخال  :  لإدخال\n",
      "أفكار  :  أفكار\n",
      "الجبر  :  الجبر\n",
      "و  :  و\n",
      "هو  :  هو\n",
      "أنه  :  أنه\n",
      "سمح  :  سمح\n",
      "بتطبيق  :  بتطبيق\n",
      "الرياضيات  :  الرياضيات\n",
      "على  :  على\n",
      "نفسها  :  نفسها\n",
      "بطريقة  :  بطريقة\n",
      "لم  :  لم\n",
      "تحدث  :  تحدث\n",
      "من  :  من\n",
      "قبل  :  قبل\n"
     ]
    }
   ],
   "source": [
    "# importing modules\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "  \n",
    "ps = PorterStemmer()\n",
    "\n",
    "words = word_tokenize(arabic_text)\n",
    "  \n",
    "for w in words:\n",
    "    print(w, \" : \", ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eaa3fc",
   "metadata": {},
   "source": [
    "# Tagging Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "242a05cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "eng_pos_tag = nltk.pos_tag(word_tokenize(english_text))\n",
    "nltk.help.upenn_tagset()\n",
    "en_pos_tag = nltk.pos_tag(word_tokenize(english_text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138883a9",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7c50862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ea9fc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perhaps', 'one', 'of', 'the', 'most', 'significant', 'advance', 'made', 'by', 'Arabic', 'mathematics', 'began', 'at', 'this', 'time', 'with', 'the', 'work', 'of', 'al-Khwarizmi', ',', 'namely', 'the', 'beginning', 'of', 'algebra', '.', 'It', 'is', 'important', 'to', 'understand', 'just', 'how', 'significant', 'this', 'new', 'idea', 'wa', '.', 'It', 'wa', 'a', 'revolutionary', 'move', 'away', 'from', 'the', 'Greek', 'concept', 'of', 'mathematics', 'which', 'wa', 'essentially', 'geometry', '.', 'Algebra', 'wa', 'a', 'unifying', 'theory', 'which', 'allowed', 'rational', 'number', ',', 'irrational', 'number', ',', 'geometrical', 'magnitude', ',', 'etc.', ',', 'to', 'all', 'be', 'treated', 'a', '``', 'algebraic', 'object', \"''\", '.', 'It', 'gave', 'mathematics', 'a', 'whole', 'new', 'development', 'path', 'so', 'much', 'broader', 'in', 'concept', 'to', 'that', 'which', 'had', 'existed', 'before', ',', 'and', 'provided', 'a', 'vehicle', 'for', 'future', 'development', 'of', 'the', 'subject', '.', 'Another', 'important', 'aspect', 'of', 'the', 'introduction', 'of', 'algebraic', 'idea', 'wa', 'that', 'it', 'allowed', 'mathematics', 'to', 'be', 'applied', 'to', 'itself', 'in', 'a', 'way', 'which', 'had', 'not', 'happened', 'before', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in word_tokenize(english_text)]\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d23b63",
   "metadata": {},
   "source": [
    "# mplementation: Chunking in NLP using nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09580ab6",
   "metadata": {},
   "source": [
    "let us try to extract all the noun phrases from a sentence using the steps defined above. First, we’ll import the required libraries and then tokenize the sentence before applying POS_tagging to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f17b93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Importing the required libraries\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk import RegexpParser\n",
    "# english_text\n",
    "english_text= \"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely \n",
    "the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from \n",
    "the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational \n",
    "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new \n",
    "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the \n",
    "subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a \n",
    "way which had not happened before.\n",
    "\"\"\"\n",
    "# Splitiing the sentence into words\n",
    "list_of_words = word_tokenize(english_text)\n",
    "# Applying POS_tagging\n",
    "tagged_words = pos_tag(list_of_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47b5a8",
   "metadata": {},
   "source": [
    " We then define our chunk keeping in mind that our aim is to extract all the noun phrases present in our sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fdad6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the Noun Phrases\n",
    "chunk_to_be_extracted = r''' Chunk: {<DT>*<NNP>*<NN>*} '''\n",
    "# Applying chunking to the text\n",
    "chunkParser = nltk.chunk.RegexpParser(chunk_to_be_extracted)\n",
    "chunked_sentence = chunkParser.parse(tagged_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce831b73",
   "metadata": {},
   "source": [
    "The ‘chunked_sentence’ variable is an NLTK tree which can be viewed using the draw() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ad2248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the NLTK tree\n",
    "chunked_sentence.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f206e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c4602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b8e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7d689d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740537c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
